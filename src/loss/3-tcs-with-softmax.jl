export FNNSoftmaxTCSLoss
export RNNSoftmaxTCSLoss
export FRNNSoftmaxTCSLoss
export FRNNSoftmaxFocalTCSLoss
export FRNNSoftmaxTCSProbs

"""
    FNNSoftmaxTCSLoss(x::Variable,
                      seqlabels::VecVecInt,
                      inputlens::VecInt;
                      background::Int=1,
                      foreground::Int=2)

# Inputs
`x`         : 2-D Variable, a batch of concatenated input sequence\n
`seqlabels` : a batch of sequential labels, like [[i,j,k],[x,y],...]\n
`inputlens` : records each input sequence's length, like [20,17,...]\n

# Structure
    â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚
    â”‚ W â”œâ”€â”€â–ºâ”€â”
    â”‚ â”‚ â”‚    â”‚
    â””â”€â”€â”€â”˜    â”‚
    â”Œâ”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”          â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚  â”Œâ”€â”´â”€â”  â”‚ â”‚ â”‚ softmax  â”‚ â”‚ â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Z â”œâ”€â–ºâ”‚ Ã— â”œâ”€â–ºâ”‚ X â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ P â”œâ”€â”€â–ºâ”‚TCSLOSSâ”‚â—„â”€â”€ (seqLabel)
    â”‚ â”‚ â”‚  â””â”€â”€â”€â”˜  â”‚ â”‚ â”‚          â”‚ â”‚ â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â””â”€â”€â”€â”˜         â””â”€â”¬â”€â”˜          â””â”€â”¬â”€â”˜       â”‚
                    â”‚              â”‚+        â–¼
                  â”Œâ”€â”´â”€â”            â–¼       â”Œâ”€â”´â”€â”
                  â”‚ â”‚ â”‚          â”Œâ”€â”´â”€â” -   â”‚ â”‚ â”‚
                  â”‚ Î´ â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ - â”‚â”€â”€â—„â”€â”€â”¤ r â”‚
                  â”‚ â”‚ â”‚          â””â”€â”€â”€â”˜     â”‚ â”‚ â”‚
                  â””â”€â”€â”€â”˜                    â””â”€â”€â”€â”˜
"""
function FNNSoftmaxTCSLoss(x::Variable{T},
                           seqlabels::VecVecInt,
                           inputlens::VecInt;
                           background::Int=1,
                           foreground::Int=2) where T
    batchsize = length(seqlabels)
    nlnp = zeros(eltype(x), batchsize)
    I, F = indexbounds(inputlens)
    p = softmax(áµ›(x); dims=1)
    r = zero(p)

    for b = 1:batchsize
        span = I[b]:F[b]
        r[:,span], nlnp[b] = TCS(p[:,span], seqlabels[b], background=background, foreground=foreground)
    end

    Î” = p - r
    y = Variable{T}([sum(nlnp)], x.backprop)

    if y.backprop
        y.backward = function âˆ‡FNNSoftmaxTCSLoss()
            if needgrad(x)
                x â† Î´(y) .* Î”
            end
        end
        addchild(y, x)
    end
    return y
end


"""
    RNNSoftmaxTCSLoss(x::Variable,
                      seqlabels::VecVecInt,
                      inputlens::VecInt;
                      reduction::String="seqlen",
                      background::Int=1,
                      foreground::Int=2)

a batch of padded input sequence is processed by neural networks into `x`

# Inputs
`x`         : 3-D Variable with shape (featdims,timesteps,batchsize), a batch of padded input sequence\n
`seqlabels` : a batch of sequential labels, like [[i,j,k],[x,y],...]\n
`inputlens` : records each input sequence's length, like [20,17,...]\n

# Structure
    â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚
    â”‚ W â”œâ”€â”€â–ºâ”€â”
    â”‚ â”‚ â”‚    â”‚
    â””â”€â”€â”€â”˜    â”‚
    â”Œâ”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”          â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚  â”Œâ”€â”´â”€â”  â”‚ â”‚ â”‚ softmax  â”‚ â”‚ â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Z â”œâ”€â–ºâ”‚ Ã— â”œâ”€â–ºâ”‚ X â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ P â”œâ”€â”€â–ºâ”‚TCSLOSSâ”‚â—„â”€â”€ (seqLabel)
    â”‚ â”‚ â”‚  â””â”€â”€â”€â”˜  â”‚ â”‚ â”‚          â”‚ â”‚ â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â””â”€â”€â”€â”˜         â””â”€â”¬â”€â”˜          â””â”€â”¬â”€â”˜       â”‚
                    â”‚              â”‚+        â–¼
                  â”Œâ”€â”´â”€â”            â–¼       â”Œâ”€â”´â”€â”
                  â”‚ â”‚ â”‚          â”Œâ”€â”´â”€â” -   â”‚ â”‚ â”‚
                  â”‚ Î´ â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ - â”‚â”€â”€â—„â”€â”€â”¤ r â”‚
                  â”‚ â”‚ â”‚          â””â”€â”€â”€â”˜     â”‚ â”‚ â”‚
                  â””â”€â”€â”€â”˜                    â””â”€â”€â”€â”˜
"""
function RNNSoftmaxTCSLoss(x::Variable{T},
                           seqlabels::VecVecInt,
                           inputlens::VecInt;
                           reduction::String="seqlen",
                           background::Int=1,
                           foreground::Int=2) where T
    batchsize = length(seqlabels)
    nlnp = zeros(eltype(x), 1, 1, batchsize)
    p = zero(áµ›(x))
    r = zero(p)

    for b = 1:batchsize
        Táµ‡ = inputlens[b]
        p[:,1:Táµ‡,b] = softmax(x.value[:,1:Táµ‡,b]; dims=1)
        r[:,1:Táµ‡,b], nlnp[b] = TCS(p[:,1:Táµ‡,b], seqlabels[b], background=background, foreground=foreground)
    end

    Î” = p - r
    l = T(nlnp)
    reduce3d(Î”, l, seqlabels, reduction)
    y = Variable{T}([sum(l)], x.backprop)

    if y.backprop
        y.backward = function âˆ‡RNNSoftmaxTCSLoss()
            if needgrad(x)
                x â† Î´(y) .* Î”
            end
        end
        addchild(y, x)
    end
    return y
end


"""
    FRNNSoftmaxTCSLoss(x::Variable,
                       seqlabels::VecVecInt;
                       reduction::String="seqlen",
                       background::Int=1,
                       foreground::Int=2)

# Main Inputs
`x`            : 3-D Variable with shape (featdims,timesteps,batchsize), resulted by a batch of padded input sequence\n
`seqlabels`    : a batch of sequential labels, like [[i,j,k],[x,y],...]\n

# Structure
    â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚
    â”‚ W â”œâ”€â”€â–ºâ”€â”
    â”‚ â”‚ â”‚    â”‚
    â””â”€â”€â”€â”˜    â”‚
    â”Œâ”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”          â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚  â”Œâ”€â”´â”€â”  â”‚ â”‚ â”‚ softmax  â”‚ â”‚ â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Z â”œâ”€â–ºâ”‚ Ã— â”œâ”€â–ºâ”‚ X â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ P â”œâ”€â”€â–ºâ”‚TCSLOSSâ”‚â—„â”€â”€ (seqLabel)
    â”‚ â”‚ â”‚  â””â”€â”€â”€â”˜  â”‚ â”‚ â”‚          â”‚ â”‚ â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â””â”€â”€â”€â”˜         â””â”€â”¬â”€â”˜          â””â”€â”¬â”€â”˜       â”‚
                    â”‚              â”‚+        â–¼
                  â”Œâ”€â”´â”€â”            â–¼       â”Œâ”€â”´â”€â”
                  â”‚ â”‚ â”‚          â”Œâ”€â”´â”€â” -   â”‚ â”‚ â”‚
                  â”‚ Î´ â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ - â”‚â”€â”€â—„â”€â”€â”¤ r â”‚
                  â”‚ â”‚ â”‚          â””â”€â”€â”€â”˜     â”‚ â”‚ â”‚
                  â””â”€â”€â”€â”˜                    â””â”€â”€â”€â”˜
"""
function FRNNSoftmaxTCSLoss(x::Variable{T},
                            seqlabels::VecVecInt;
                            reduction::String="seqlen",
                            background::Int=1,
                            foreground::Int=2) where T
    featdims, timesteps, batchsize = size(x)
    nlnp = zeros(eltype(x), 1, 1, batchsize)
    p = softmax(áµ›(x); dims=1)
    r = zero(p)

    for b = 1:batchsize
        r[:,:,b], nlnp[b] = TCS(p[:,:,b], seqlabels[b], background=background, foreground=foreground)
    end

    Î” = p - r
    l = T(nlnp)
    reduce3d(Î”, l, seqlabels, reduction)
    y = Variable{T}([sum(l)], x.backprop)

    if y.backprop
        y.backward = function âˆ‡FRNNSoftmaxTCSLoss()
            if needgrad(x)
                x â† Î´(y) .* Î”
            end
        end
        addchild(y, x)
    end
    return y
end


function FRNNSoftmaxTCSProbs(x::Variable{T},
                             seqlabels::VecVecInt;
                             background::Int=1,
                             foreground::Int=2) where T
    featdims, timesteps, batchsize = size(x)
    nlnp = zeros(eltype(x), 1, 1, batchsize)
    p = softmax(áµ›(x); dims=1)
    r = zero(p)

    for b = 1:batchsize
        r[:,:,b], nlnp[b] = TCS(p[:,:,b], seqlabels[b], background=background, foreground=foreground)
    end

    ğ’‘ = Variable{T}(exp(T(-nlnp)), x.backprop)
    Î” = r - p

    if ğ’‘.backprop
        ğ’‘.backward = function âˆ‡FRNNSoftmaxCTCProbs()
            if needgrad(x)
                x â† Î´(ğ’‘)  .* áµ›(ğ’‘) .* Î”
            end
        end
        addchild(ğ’‘, x)
    end
    return ğ’‘
end


function FRNNSoftmaxFocalTCSLoss(x::Variable{T},
                                 seqlabels::VecVecInt;
                                 reduction::String="seqlen",
                                 background::Int=1,
                                 foreground::Int=2,
                                 focus::Real=1.0f0) where T
    featdims, timesteps, batchsize = size(x)
    S = eltype(x)
    nlnp = zeros(S, 1, 1, batchsize)
    p = softmax(áµ›(x), dims=1)
    r = zero(p)
    ğœ¸ = S(focus)
    ğŸ™ = S(1.0f0)

    for b = 1:batchsize
        r[:,:,b], nlnp[b] = TCS(p[:,:,b], seqlabels[b], background=background, foreground=foreground)
    end

    ğ’ğ’ğ’‘ = T(-nlnp)
    ğ’‘ = exp(ğ’ğ’ğ’‘)
    ğ’Œ = @.  (ğŸ™ - ğ’‘)^(ğœ¸-ğŸ™) * (ğŸ™ - ğ’‘ - ğœ¸*ğ’‘*ğ’ğ’ğ’‘)
    t = @. -(ğŸ™ - ğ’‘)^ğœ¸ * ğ’ğ’ğ’‘
    Î” = p - r
    reduce3d(Î”, t, seqlabels, reduction)
    y = Variable{T}([sum(t)], x.backprop)

    if y.backprop
        y.backward = function âˆ‡FRNNSoftmaxFocalTCSLoss()
            if needgrad(x)
                x â† Î´(y) .* ğ’Œ .* Î”
            end
        end
        addchild(y, x)
    end
    return y
end
