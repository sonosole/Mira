## probabilistic loss

export CrossEntropy
export CrossEntropyLoss

export BinaryCrossEntropy
export BinaryCrossEntropyLoss

export FocalCE
export FocalCELoss
export FocalBCE
export FocalBCELoss

export NLogCrossEntropy
export NLogCELoss

export InvPowerCrossEntropy
export InvPowerCELoss


"""
    CrossEntropy(p::Variable{T}, label::Variable{T}) -> y::Variable{T}
cross entropy is `y = - label * log(p)` where `p` is the output of the network.
"""
function CrossEntropy(p::Variable{T}, label::Variable{T}) where T
    @assert (p.shape == label.shape)
    backprop = (p.backprop || label.backprop)
    Ïµ = eltype(p)(1e-38)
    ğ† = value(label)
    ğ’‘ = value(p) .+ Ïµ

    y = Variable{T}(- ğ† .* log.(ğ’‘), backprop)
    if backprop
        y.backward = function âˆ‡CrossEntropy()
            if need2computeÎ´!(p)
                p â† - Î´(y) .* ğ† ./ ğ’‘
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, p)
    end
    return y
end


"""
    CrossEntropy(p::Variable, label::AbstractArray) -> y::Variable
cross entropy is `y = - label * log(p)` where `p` is the output of the network.
"""
function CrossEntropy(p::Variable{T}, label::AbstractArray) where T
    @assert p.shape == size(label)
    Ïµ = eltype(p)(1e-38)
    ğ’‘ = value(p) .+ Ïµ
    ğ† = label

    y = Variable{T}(- ğ† .* log.(ğ’‘), p.backprop)
    if y.backprop
        y.backward = function âˆ‡CrossEntropy()
            if need2computeÎ´!(p)
                p â† - Î´(y) .* ğ† ./ ğ’‘
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, p)
    end
    return y
end


"""
    CrossEntropy(p::AbstractArray, label::AbstractArray) -> lossvalue::AbstractArray
cross entropy is `y = - label * log(p)` where `p` is the output of the network.
"""
function CrossEntropy(p::AbstractArray, label::AbstractArray)
    @assert size(p) == size(label)
    Ïµ = eltype(p)(1e-38)
    y = - label .* log.(p .+ Ïµ)
    return y
end


"""
    BinaryCrossEntropy(p::Variable{T}, label::Variable{T}) -> y::Variable{T}
binary cross entropy is `y = - label*log(p) - (1-label)*log(1-p)` where `p` is the output of the network.
"""
function BinaryCrossEntropy(p::Variable{T}, label::Variable{T}) where T
    @assert (p.shape == label.shape)
    backprop = (p.backprop || label.backprop)
    TO = eltype(p)
    Ïµ  = TO(1e-38)
    l  = TO(1.0f0)
    ğ†  = áµ›(label)
    ğ’‘  = áµ›(p)
    pâº = ğ’‘ .+ Ïµ
    pâ» = ğ’‘ .- Ïµ

    tâ‚ = @. -      ğ†  * log(    pâº)
    tâ‚‚ = @. - (l - ğ†) * log(l - pâ»)
    y  = Variable{T}(tâ‚ + tâ‚‚, backprop)
    if backprop
        y.backward = function âˆ‡BinaryCrossEntropy()
            if need2computeÎ´!(p)
                Î´â‚ = @. (l - ğ†) / (l - pâ»)
                Î´â‚‚ = @.      ğ†  /      pâº
                p â† Î´(y) .* (Î´â‚ - Î´â‚‚)
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, p)
    end
    return y
end


"""
    BinaryCrossEntropy(p::Variable, label::AbstractArray) -> y::Variable
binary cross entropy is `y = - label*log(p) - (1-label)*log(1-p)` where `p` is the output of the network.
"""
function BinaryCrossEntropy(p::Variable{T}, label::AbstractArray) where T
    @assert p.shape == size(label)
    TO = eltype(p)
    Ïµ  = TO(1e-38)
    l  = TO(1.0f0)
    ğ†  = label
    ğ’‘  = áµ›(p)
    pâº = ğ’‘ .+ Ïµ
    pâ» = ğ’‘ .- Ïµ

    tâ‚ = @. -      ğ†  * log(    pâº)
    tâ‚‚ = @. - (l - ğ†) * log(l - pâ»)
    y  = Variable{T}(tâ‚ + tâ‚‚, p.backprop)
    if y.backprop
        y.backward = function âˆ‡BinaryCrossEntropy()
            if need2computeÎ´!(p)
                Î´â‚ = @. (l - ğ†) / (l - pâ»)
                Î´â‚‚ = @.      ğ†  /      pâº
                p â† Î´(y) .* (Î´â‚ - Î´â‚‚)
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, p)
    end
    return y
end


"""
    BinaryCrossEntropy(p::AbstractArray, label::AbstractArray) -> lossvalue::AbstractArray
binary cross entropy is `y = - label*log(p) - (1-label)*log(1-p)` where `p` is the output of the network.
"""
function BinaryCrossEntropy(p::AbstractArray, label::AbstractArray)
    @assert size(p) == size(label)
    TO = eltype(p)
    Ïµ  = TO(1e-38)
    l  = TO(1.0f0)
    tâ‚ = @. -      label  * log(    p + Ïµ)
    tâ‚‚ = @. - (l - label) * log(l - p + Ïµ)
    return tâ‚ + tâ‚‚
end


CrossEntropyLoss(x::Variable{T}, label::Variable{T}; reduction::String="sum") where T = Loss( CrossEntropy(x, label), reduction=reduction )
CrossEntropyLoss(x::Variable{T}, label::AbstractArray; reduction::String="sum") where T = Loss( CrossEntropy(x, label), reduction=reduction )
CrossEntropyLoss(x::AbstractArray, label::AbstractArray; reduction::String="sum") = Loss( CrossEntropy(x, label), reduction=reduction )

BinaryCrossEntropyLoss(x::Variable{T}, label::Variable{T}; reduction::String="sum") where T = Loss(BinaryCrossEntropy(x, label), reduction=reduction)
BinaryCrossEntropyLoss(x::Variable{T}, label::AbstractArray; reduction::String="sum") where T = Loss(BinaryCrossEntropy(x, label), reduction=reduction)
BinaryCrossEntropyLoss(x::AbstractArray, label::AbstractArray; reduction::String="sum") = Loss(BinaryCrossEntropy(x, label), reduction=reduction)


"""
    FocalBCE(p::Variable, label::AbstractArray; focus::Real=1.0f0, alpha::Real=0.5f0)

focal loss version of BinaryCrossEntropy:\n
`loss = Î± * (1-p)áµ * [- label * ln(p)] + (1 - Î±) * páµ * [-(1-label) * ln(1-p)]`\n
where `Î³` is the `focus` value, `Î±` is the weight for positive class.
"""
function FocalBCE(p::Variable{T}, label::AbstractArray; focus::Real=1.0f0, alpha::Real=0.5f0) where T
    @assert p.shape == size(label)
    TO = eltype(p)
    Ïµ  = TO(1e-38)
    l  = TO(1.0f0)
    Î³  = TO(focus)
    Î±  = TO(alpha)
    ğ†  = label
    ğ’‘  = áµ›(p)
    pâº = ğ’‘ .+ Ïµ
    pâ» = ğ’‘ .- Ïµ

    wâ‚ = @. -      Î±  *      ğ†
    wâ‚‚ = @. - (l - Î±) * (l - ğ†)

    tâ‚ = @. wâ‚ * (l - pâ») ^ Î³ * log(    pâº)
    tâ‚‚ = @. wâ‚‚ *      pâº  ^ Î³ * log(l - pâ»)

    y  = Variable{T}(tâ‚ + tâ‚‚, p.backprop)

    if y.backprop
        y.backward = function âˆ‡FocalBCE()
            if need2computeÎ´!(p)
                Î´â‚ = @. wâ‚ * (l - pâ»)^(Î³ - l) * (l / pâº - Î³ * log(pâº) - l)
                Î´â‚‚ = @. wâ‚‚ * pâº ^ Î³ * (l / (pâ» - l) + Î³ * log(l - pâ») / pâº)
                p â† Î´(y) .* (Î´â‚ + Î´â‚‚)
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, p)
    end
    return y
end


"""
    FocalCE(p::Variable, label::AbstractArray; focus::Real=1.0f0) -> y::Variable

focal loss version of CrossEntropy:\n
`loss = (1-p)áµ * [- label * ln(p)]`, \n
where `Î³` is the `focus` value.
"""
function FocalCE(p::Variable{T}, label::AbstractArray; focus::Real=1.0f0) where T
    @assert p.shape == size(label)
    TO = eltype(p)
    Ïµ  = TO(1e-38)  # alias for value closing to zero
    l  = TO(1.0f0)  # alias for value one
    Î³  = TO(focus)
    ğ†  = label
    ğ’‘  = value(p)
    pâº = ğ’‘ .+ Ïµ    # little greater
    pâ» = ğ’‘ .- Ïµ    # little smaller

    t = @. (l - pâ») ^ Î³ * (- ğ† * log(pâº))
    y = Variable{T}(t, p.backprop)

    if y.backprop
        y.backward = function âˆ‡FocalCE()
            if need2computeÎ´!(p)
                n  = Î³ - l
                Î´p = Î´(p)
                Î´y = Î´(y)
                p  â† @. Î´y * ğ† * (l - pâ»)^n * (Î³ * log(pâº) + l - l / pâº)
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, p)
    end
    return y
end

"""
    FocalCELoss(x::Variable,
                label::AbstractArray;
                focus::Real=1.0f0,
                reduction::String="sum")

focal loss version CrossEntropyLoss
"""
function FocalCELoss(x::Variable{T},
                     label::AbstractArray;
                     focus::Real=1.0f0,
                     reduction::String="sum") where T
    return Loss(FocalCE(x, label, focus=focus), reduction=reduction)
end


"""
    FocalBCELoss(x::Variable,
                 label::AbstractArray;
                 focus::Real=1.0f0,
                 alpha::Real=0.5f0,
                 reduction::String="sum")

focal loss version BinaryCrossEntropyLoss
"""
function FocalBCELoss(x::Variable{T},
                      label::AbstractArray;
                      focus::Real=1.0f0,
                      alpha::Real=0.5f0,
                      reduction::String="sum") where T
    return Loss(FocalBCE(x, label, focus=focus, alpha=alpha), reduction=reduction)
end


"""
    NLogCrossEntropy(p::Variable, label::AbstractArray)
Loss = [ âˆ’ ln(`p`) ] * [ âˆ’ `label` * ln(`p`) ], where `p` is the predicted probability
"""
function NLogCrossEntropy(p::Variable{T}, label::AbstractArray) where T
    # Loss = (-ğ’ğ’ğ’‘)*(-ğœ¸ * ğ’ğ’ğ’‘), negative log weighted CELoss
    @assert p.shape == size(label)
    S = eltype(p)
    Ïµ = S(1e-38)
    ğœ¸ = label
    ğ’‘ = áµ›(p) .+ Ïµ
    ğ’ğ’ğ’‘ = log.(ğ’‘)
    y = Variable{T}(ğœ¸ .* ğ’ğ’ğ’‘ .* ğ’ğ’ğ’‘, p.backprop)
    if y.backprop
        ğŸ = S(2f0)
        y.backward = function âˆ‡NLogCrossEntropy()
            if need2computeÎ´!(p)
                p â† Î´(y) .* ğŸ .* ğœ¸ .* ğ’ğ’ğ’‘ ./ ğ’‘
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, p)
    end
    return y
end


function NLogCELoss(p::Variable, label::AbstractArray; reduction::String="sum")
    return Loss(NLogCrossEntropy(p, label), reduction=reduction)
end


"""
    InvPowerCrossEntropy(p::Variable{T}, label::AbstractArray; a::Real=0.3f0, n::Real=1f0)
Loss = [ 1 / (`p` + (1-`a`))`â¿` ] * [ âˆ’ `label` * ln(`p`) ], where `p` is the predicted probability.
`a` in [0, 0.5] is recommended.
"""
function InvPowerCrossEntropy(p::Variable{T}, label::AbstractArray; a::Real=0.3f0, n::Real=1f0) where T
    @assert p.shape == size(label)
    S = eltype(p)
    Ïµ = S(1e-38)
    a = S(1 - a)
    ğ’ = S(n)

    ğœ¸ = label
    ğ’‘ = áµ›(p) .+ Ïµ
    ğ’ğ’ğ’‘  = log.(ğ’‘)
    Q    = ğ’‘ .+ a
    Qâ¿   = Q .^ ğ’
    Qâ¿âºÂ¹ = Q .* Qâ¿
    y = Variable{T}( - ğœ¸ .* ğ’ğ’ğ’‘ ./ Qâ¿ , p.backprop)

    if y.backprop
        y.backward = function âˆ‡InvPowerCrossEntropy()
            if need2computeÎ´!(p)
                Î´y = Î´(y)
                Î´p = Î´(p)
                p  â† @. Î´y * ğœ¸ * (ğ’ * ğ’‘ * ğ’ğ’ğ’‘ - Q) / (ğ’‘ * Qâ¿âºÂ¹)
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, p)
    end
    return y
end


function InvPowerCELoss(p::Variable,
                        label::AbstractArray;
                        reduction::String="sum",
                        a::Real=0.3f0,
                        n::Real=1.0f0)
    return Loss(InvPowerCrossEntropy(p, label, a=a, n=n), reduction=reduction)
end
