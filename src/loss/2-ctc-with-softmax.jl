export DNNSoftmaxCTCLossSingleSeq
export FNNSoftmaxCTCLoss
export RNNSoftmaxCTCLoss
export FRNNSoftmaxCTCLoss
export FRNNSoftmaxFocalCTCLoss
export FRNNSoftmaxCTCProbs
export SoftmaxCTCFocalCELoss
export SoftmaxCTCInvPowerCELoss
export SoftmaxCTCLikeWeightedCELoss
export SoftmaxCTCLikeFocalCELoss

"""
    DNNSoftmaxCTCLossSingleSeq(x::Variable{T}, seq::VecInt; blank::Int=1, weight=1.0)

case batchsize==1 for test case. `x` is the output of a whole complete input sequence

# Inputs
`x`      : 2-D Variable, input sequence\n
`seq`    : 1-D Array, input sequence's label\n
`weight` : weight for CTC loss

# Structure
    â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚
    â”‚ W â”œâ”€â”€â–ºâ”€â”
    â”‚ â”‚ â”‚    â”‚
    â””â”€â”€â”€â”˜    â”‚
    â”Œâ”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”          â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚  â”Œâ”€â”´â”€â”  â”‚ â”‚ â”‚ softmax  â”‚ â”‚ â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Z â”œâ”€â–ºâ”‚ Ã— â”œâ”€â–ºâ”‚ X â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ P â”œâ”€â”€â–ºâ”‚CTCLOSSâ”‚â—„â”€â”€ (seqLabel)
    â”‚ â”‚ â”‚  â””â”€â”€â”€â”˜  â”‚ â”‚ â”‚          â”‚ â”‚ â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â””â”€â”€â”€â”˜         â””â”€â”¬â”€â”˜          â””â”€â”¬â”€â”˜       â”‚
                    â”‚              â”‚+        â–¼
                  â”Œâ”€â”´â”€â”            â–¼       â”Œâ”€â”´â”€â”
                  â”‚ â”‚ â”‚          â”Œâ”€â”´â”€â” -   â”‚ â”‚ â”‚
                  â”‚ Î´ â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ - â”‚â”€â”€â—„â”€â”€â”¤ r â”‚
                  â”‚ â”‚ â”‚          â””â”€â”€â”€â”˜     â”‚ â”‚ â”‚
                  â””â”€â”€â”€â”˜                    â””â”€â”€â”€â”˜
"""
function DNNSoftmaxCTCLossSingleSeq(x::Variable{T}, seq::VecInt; blank::Int=1, weight=1.0) where T
    p = softmax(áµ›(x), dims=1)
    L = length(seq) * 2 + 1
    r, nlnp = CTC(p, seq, blank=blank)

    Î” = p - r
    y = Variable{T}([nlnp], x.backprop)

    if y.backprop
        y.backward = function âˆ‡DNNSoftmaxCTCLossSingleSeq()
            if need2computeÎ´!(x)
                if weight==1.0
                    Î´(x) .+= Î´(y) .* Î”
                else
                    Î´(x) .+= Î´(y) .* Î” .* weight
                end
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, x)
    end
    return y
end


"""
    FNNSoftmaxCTCLoss(x::Variable{T}, seqlabels::VecVecInt, inputlens; blank=1, weight=1.0) where T

a batch of concatenated input sequence is processed by neural networks into `x`

# Inputs
`x`         : 2-D Variable, inputs of softmax\n
`seqlabels` : a batch of sequential labels, like [[i,j,k],[x,y],...]\n
`inputlens` : records each input sequence's length, like [20,17,...]\n
`weight`    : weight for CTC loss

# Structure
    â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚
    â”‚ W â”œâ”€â”€â–ºâ”€â”
    â”‚ â”‚ â”‚    â”‚
    â””â”€â”€â”€â”˜    â”‚
    â”Œâ”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”          â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚  â”Œâ”€â”´â”€â”  â”‚ â”‚ â”‚ softmax  â”‚ â”‚ â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Z â”œâ”€â–ºâ”‚ Ã— â”œâ”€â–ºâ”‚ X â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ P â”œâ”€â”€â–ºâ”‚CTCLOSSâ”‚â—„â”€â”€ (seqLabel)
    â”‚ â”‚ â”‚  â””â”€â”€â”€â”˜  â”‚ â”‚ â”‚          â”‚ â”‚ â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â””â”€â”€â”€â”˜         â””â”€â”¬â”€â”˜          â””â”€â”¬â”€â”˜       â”‚
                    â”‚              â”‚+        â–¼
                  â”Œâ”€â”´â”€â”            â–¼       â”Œâ”€â”´â”€â”
                  â”‚ â”‚ â”‚          â”Œâ”€â”´â”€â” -   â”‚ â”‚ â”‚
                  â”‚ Î´ â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ - â”‚â”€â”€â—„â”€â”€â”¤ r â”‚
                  â”‚ â”‚ â”‚          â””â”€â”€â”€â”˜     â”‚ â”‚ â”‚
                  â””â”€â”€â”€â”˜                    â””â”€â”€â”€â”˜
"""
function FNNSoftmaxCTCLoss(x::Variable{T},
                           seqlabels::VecVecInt,
                           inputlens::VecInt;
                           blank::Int=1,
                           weight=1.0) where T
    batchsize = length(inputLengths)
    nlnp = zeros(eltype(x), batchsize)
    I, F = indexbounds(inputlens)
    p = softmax(áµ›(x), dims=1)
    r = zero(p)

    for b = 1:batchsize
        span = I[b]:F[b]
        r[:,span], nlnp[b] = CTC(p[:,span], seqlabels[b], blank=blank)
    end

    Î” = p - r
    y = Variable{T}([sum(nlnp)], x.backprop)

    if y.backprop
        y.backward = function âˆ‡FNNSoftmaxCTCLoss()
            if need2computeÎ´!(x)
                if weight==1.0
                    Î´(x) .+= Î´(y) .* Î”
                else
                    Î´(x) .+= Î´(y) .* Î” .* weight
                end
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, x)
    end
    return y
end


"""
    RNNSoftmaxCTCLoss(x::Variable{T}, seqlabels::VecVecInt, inputlens; blank=1, weight=1.0) where T

a batch of padded input sequence is processed by neural networks into `x`

# Inputs
`x`         : 3-D Variable with shape (featdims,timesteps,batchsize), inputs of softmax\n
`seqlabels` : a batch of sequential labels, like [[i,j,k],[x,y],...]\n
`inputlens` : each input's length, like [19,97,...]\n
`weight`    : weight for CTC loss

# Structure
    â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚
    â”‚ W â”œâ”€â”€â–ºâ”€â”
    â”‚ â”‚ â”‚    â”‚
    â””â”€â”€â”€â”˜    â”‚
    â”Œâ”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”          â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚  â”Œâ”€â”´â”€â”  â”‚ â”‚ â”‚ softmax  â”‚ â”‚ â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Z â”œâ”€â–ºâ”‚ Ã— â”œâ”€â–ºâ”‚ X â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ P â”œâ”€â”€â–ºâ”‚CTCLOSSâ”‚â—„â”€â”€ (seqLabel)
    â”‚ â”‚ â”‚  â””â”€â”€â”€â”˜  â”‚ â”‚ â”‚          â”‚ â”‚ â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â””â”€â”€â”€â”˜         â””â”€â”¬â”€â”˜          â””â”€â”¬â”€â”˜       â”‚
                    â”‚              â”‚+        â–¼
                  â”Œâ”€â”´â”€â”            â–¼       â”Œâ”€â”´â”€â”
                  â”‚ â”‚ â”‚          â”Œâ”€â”´â”€â” -   â”‚ â”‚ â”‚
                  â”‚ Î´ â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ - â”‚â”€â”€â—„â”€â”€â”¤ r â”‚
                  â”‚ â”‚ â”‚          â””â”€â”€â”€â”˜     â”‚ â”‚ â”‚
                  â””â”€â”€â”€â”˜                    â””â”€â”€â”€â”˜
"""
function RNNSoftmaxCTCLoss(x::Variable{T},
                           seqlabels::VecVecInt,
                           inputlens::VecInt;
                           blank::Int=1,
                           weight=1.0) where T
    batchsize = length(inputlens)
    nlnp = zeros(eltype(x), 1, 1, batchsize)
    p = zero(áµ›(x))
    r = zero(p)

    for b = 1:batchsize
        Táµ‡ = inputlens[b]
        p[:,1:Táµ‡,b] = softmax(x.value[:,1:Táµ‡,b]; dims=1)
        r[:,1:Táµ‡,b], nlnp[b] = CTC(p[:,1:Táµ‡,b], seqlabels[b], blank=blank)
    end

    Î” = p - r
    l = T(nlnp)
    reduce3d(Î”, l, seqlabels, reduction)
    y = Variable{T}([sum(l)], x.backprop)

    if y.backprop
        y.backward = function âˆ‡RNNSoftmaxCTCLoss()
            if need2computeÎ´!(x)
                if weight==1.0
                    Î´(x) .+= Î´(y) .* Î”
                else
                    Î´(x) .+= Î´(y) .* Î” .* weight
                end
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, x)
    end
    return y
end


"""
    FRNNSoftmaxCTCLoss(x::Variable{T}, seqlabels::VecVecInt; blank=1, weight=1.0) where T

a batch of padded input sequence is processed by neural networks into `x`

# Inputs
`x`         : 3-D Variable (featdims,timesteps,batchsize), inputs of softmax\n
`seqlabels` : a batch of sequential labels, like [[i,j,k],[x,y],...]\n
`weight`    : weight for CTC loss

# Structure
    â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚
    â”‚ W â”œâ”€â”€â–ºâ”€â”
    â”‚ â”‚ â”‚    â”‚
    â””â”€â”€â”€â”˜    â”‚
    â”Œâ”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”          â”Œâ”€â”€â”€â”
    â”‚ â”‚ â”‚  â”Œâ”€â”´â”€â”  â”‚ â”‚ â”‚ softmax  â”‚ â”‚ â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Z â”œâ”€â–ºâ”‚ Ã— â”œâ”€â–ºâ”‚ X â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ P â”œâ”€â”€â–ºâ”‚CTCLOSSâ”‚â—„â”€â”€ (seqLabel)
    â”‚ â”‚ â”‚  â””â”€â”€â”€â”˜  â”‚ â”‚ â”‚          â”‚ â”‚ â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â””â”€â”€â”€â”˜         â””â”€â”¬â”€â”˜          â””â”€â”¬â”€â”˜       â”‚
                    â”‚              â”‚+        â–¼
                  â”Œâ”€â”´â”€â”            â–¼       â”Œâ”€â”´â”€â”
                  â”‚ â”‚ â”‚          â”Œâ”€â”´â”€â” -   â”‚ â”‚ â”‚
                  â”‚ Î´ â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ - â”‚â”€â”€â—„â”€â”€â”¤ r â”‚
                  â”‚ â”‚ â”‚          â””â”€â”€â”€â”˜     â”‚ â”‚ â”‚
                  â””â”€â”€â”€â”˜                    â””â”€â”€â”€â”˜
"""
function FRNNSoftmaxCTCLoss(x::Variable{T},
                            seqlabels::VecVecInt;
                            reduction::String="seqlen",
                            blank::Int=1,
                            weight=1.0) where T
    featdims, timesteps, batchsize = size(x)
    nlnp = zeros(eltype(x), 1, 1, batchsize)
    p = softmax(áµ›(x), dims=1)
    r = zero(p)

    for b = 1:batchsize
        r[:,:,b], nlnp[b] = CTC(p[:,:,b], seqlabels[b], blank=blank)
    end

    Î” = p - r
    l = T(nlnp)
    reduce3d(Î”, l, seqlabels, reduction)
    y = Variable{T}([sum(l)], x.backprop)

    if y.backprop
        y.backward = function âˆ‡FRNNSoftmaxCTCLoss()
            if need2computeÎ´!(x)
                if weight==1.0
                    Î´(x) .+= Î´(y) .* Î”
                else
                    Î´(x) .+= Î´(y) .* Î” .* weight
                end
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, x)
    end
    return y
end



function FRNNSoftmaxFocalCTCLoss(x::Variable{T},
                                 seqlabels::VecVecInt;
                                 reduction::String="seqlen",
                                 blank::Int=1,
                                 focus::Real=1.0f0,
                                 weight=1.0) where T
    featdims, timesteps, batchsize = size(x)
    S = eltype(x)
    nlnp = zeros(S, 1, 1, batchsize)
    p = softmax(áµ›(x), dims=1)
    r = zero(p)
    ğœ¸ = S(focus)
    ğŸ™ = S(1.0f0)

    for b = 1:batchsize
        r[:,:,b], nlnp[b] = CTC(p[:,:,b], seqlabels[b], blank=blank)
    end

    ğ’ğ’ğ’‘ = T(-nlnp)
    ğ’‘ = exp(ğ’ğ’ğ’‘)
    ğ’Œ = @.  (ğŸ™ - ğ’‘)^(ğœ¸-ğŸ™) * (ğŸ™ - ğ’‘ - ğœ¸*ğ’‘*ğ’ğ’ğ’‘)
    t = @. -(ğŸ™ - ğ’‘)^ğœ¸ * ğ’ğ’ğ’‘
    Î” = p - r
    reduce3d(Î”, t, seqlabels, reduction)
    y = Variable{T}([sum(t)], x.backprop)

    if y.backprop
        y.backward = function âˆ‡FRNNSoftmaxFocalCTCLoss()
            if need2computeÎ´!(x)
                if weight==1.0
                    Î´(x) .+= Î´(y) .* ğ’Œ .* Î”
                else
                    Î´(x) .+= Î´(y) .* ğ’Œ .* Î” .* S(weight)
                end
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, x)
    end
    return y
end


"""
    FRNNSoftmaxCTCProbs(x::Variable, seqlabels::VecVecInt; blank::Int=1) -> p::Variable

# Inputs
`x`         : 3-D Variable (featdims,timesteps,batchsize), input of softmax\n
`seqlabels` : a batch of sequential labels, like [[i,j,k],[x,y],...]\n
`weight`    : weight for CTC loss

# Output
`p`         : 3-D Variable (1,1,batchsize), i.e. `p` is the probabilities of each sequence
"""
function FRNNSoftmaxCTCProbs(x::Variable{T}, seqlabels::VecVecInt; blank::Int=1) where T
    S = eltype(x)
    featdims, timesteps, batchsize = size(x)
    nlnp = zeros(S, 1, 1, batchsize)
    p = softmax(áµ›(x), dims=1)
    r = zero(p)

    for b = 1:batchsize
        r[:,:,b], nlnp[b] = CTC(p[:,:,b], seqlabels[b], blank=blank)
    end

    ğ’‘ = Variable{T}(exp(T(-nlnp)), x.backprop)
    Î” = r - p

    if ğ’‘.backprop
        ğ’‘.backward = function âˆ‡FRNNSoftmaxCTCProbs()
            if need2computeÎ´!(x)
                Î´(x) .+= Î´(ğ’‘) .* áµ›(ğ’‘) .*  Î”
            end
            ifNotKeepÎ´ThenFreeÎ´!(ğ’‘)
        end
        addchild(ğ’‘, x)
    end
    return ğ’‘
end


function SoftmaxCTCFocalCELoss(x::Variable,
                               seqlabels::VecVecInt;
                               reduction::String="seqlen",
                               focus::Real=0.5f0,
                               blank::Int=1)

    featdims, timesteps, batchsize = size(x)
    p = softmax(x, dims=1)
    r = zero(áµ›(x))

    for b = 1:batchsize
        r[:,:,b], _ = CTC(p.value[:,:,b], seqlabels[b], blank=blank)
    end
    fce = FocalCE(p, r, focus=focus)
    return Loss(weightseqvar(fce, seqlabels, reduction))
end


function SoftmaxCTCInvPowerCELoss(x::Variable,
                                  seqlabels::VecVecInt;
                                  reduction::String="seqlen",
                                  blank::Int=1,
                                  a::Int=0.3f0,
                                  n::Int=1.0f0)
    featdims, timesteps, batchsize = size(x)
    p = softmax(x, dims=1)
    r = zero(áµ›(x))

    for b = 1:batchsize
        r[:,:,b], _ = CTC(p.value[:,:,b], seqlabels[b], blank=blank)
    end
    ce = InvPowerCrossEntropy(p, r, a=a, n=n)
    return Loss(weightseqvar(ce, seqlabels, reduction))
end


function SoftmaxCTCLikeWeightedCELoss(x::Variable,
                                      seqlabels::VecVecInt;
                                      reduction::String="seqlen",
                                      gammafn::Function=CTC,
                                      weightfn::Function=t->(1-t))
    featdims, timesteps, batchsize = size(x)
    p = softmax(x, dims=1)
    r = zero(áµ›(x))

    for b = 1:batchsize
        r[:,:,b], _ = gammafn(p.value[:,:,b], seqlabels[b])
    end
    wce = weightfn(p) .* CrossEntropy(p, r)
    return Loss(weightseqvar(wce, seqlabels, reduction))
end


function SoftmaxCTCLikeFocalCELoss(x::Variable{T},
                                   seqlabels::VecVecInt;
                                   reduction::String="seqlen",
                                   gammafn::Function=CTC,
                                   focus::Real=0.5f0) where T

    featdims, timesteps, batchsize = size(x)
    ğ’‘ = softmax(áµ›(x), dims=1)
    ğœ¸ = zero(ğ’‘)

    for b = 1:batchsize
        ğœ¸[:,:,b], _ = gammafn(ğ’‘[:,:,b], seqlabels[b])
    end

    TO = eltype(ğ’‘)
    Ïµ  = TO(1e-38)
    ğ’  = TO(1.0f0)
    ğ’ = TO(focus)

    pâº  = ğ’‘ .+ Ïµ    # a little greater
    pâ»  = ğ’‘ .- Ïµ    # a little smaller
    ğ’ğ’ğ’‘ = log.(pâº)  # alias for log(p)
    ğ’ğ’”ğ’‘ = ğ’ .- pâ»   # alias for 1 - p

    t = @. - ğœ¸ * ğ’ğ’”ğ’‘ ^ ğ’ * ğ’ğ’ğ’‘
    y = Variable{T}(t, x.backprop)

    if y.backprop
        ğ’› = @. ğœ¸ * ğ’ğ’”ğ’‘^(ğ’-ğ’) * (ğ’ * ğ’‘ * ğ’ğ’ğ’‘ - ğ’ğ’”ğ’‘)
        y.backward = function âˆ‡SoftmaxCTCLikeFocalCELoss()
            if need2computeÎ´!(x)
                Î´(x) .+= Î´(y) .* (ğ’› .- ğ’‘ .* sum(ğ’›, dims=1))
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, x)
    end
    return Loss(weightseqvar(y, seqlabels, reduction))
end


export SoftmaxIterativeCTCLikeLoss
function SoftmaxIterativeCTCLikeLoss(x::Variable{T},
                                     seqlabels::VecVecInt;
                                     reduction::String="seqlen",
                                     blank::Int=1,
                                     ratio::Real=0.9) where T
    featdims, timesteps, batchsize = size(x)
    nlnp = zeros(eltype(x), 1, 1, batchsize)
    p = softmax(áµ›(x), dims=1)
    r = zero(p)

    for b = 1:batchsize
        r[:,:,b], nlnp[b] = CTC(p[:,:,b], seqlabels[b], blank=blank)
    end

    l = T(nlnp)
    Î” = p - modifygamma(r, seqlabels, ratio, blank, T)
    reduce3d(Î”, l, seqlabels, reduction)
    y = Variable{T}([sum(l)], x.backprop)

    if y.backprop
        y.backward = function âˆ‡FRNNSoftmaxCTCLoss()
            if need2computeÎ´!(x)
                if weight==1.0
                    Î´(x) .+= Î´(y) .* Î”
                else
                    Î´(x) .+= Î´(y) .* Î” .* weight
                end
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        addchild(y, x)
    end
    return y
end
