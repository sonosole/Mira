export BatchNorm

"""
    bn_shape_and_rdims(ndims::Int, dim::Int, chs::Int) -> shape::Dims, reducingdims::Dims

Return the affine vars' shape and reducing dims.
+ `ndims` is the number of dims of `BatchNorm`
+ `dim` is the channel-dim
+ `chs` is the number of channels
"""
function bn_shape_and_rdims(ndims::Int, dim::Int, chs::Int)
    @assert ndims â‰¥ dim "total dims shall NOT be smaller than channel-dim"
    shape = ntuple(i -> i==dim ? chs : 1, ndims)
    rdims = ntuple(i -> i>=dim ? i+1 : i, ndims-1)
    return shape, rdims
end


"""
# Explanation
Applies mean and variance normalization over a N-dimensional input `x`. Suppose `x` has
shape (C, `W1,W2,...,Wd`, B), and reshape `x` to shape (C, `T`, B), Each element of `Î¼` and `Ïƒ`
are collected from each channle of all samples, i.e.
+ Î¼[c] = mean(x[c, 1:T, 1:B]), c âˆˆ 1:C
+ Ïƒ[c] =  std(x[c, 1:T, 1:B]), c âˆˆ 1:C
finally, the shape of `Î¼` or `Ïƒ` is (C, `1,1,...,1`, 1).
# Constructor
    BatchNorm(;ndims    :: Int,                  # how many dimentions the input data has
               dim      :: Int,                  # channle dim
               channels :: Int,                  # channle size
               inertia  :: AbstractFloat=0.9,    # smoothing const or historical inertia
               eps      :: AbstractFloat=1e-38,
               type     :: Type=Array{Float32})

# N-dimentional Constructor
+ BatchNorm0d(channels::Int; inertia=0.9, eps=1e-38, type=Array{Float32}) where D
+ BatchNorm1d(channels::Int; inertia=0.9, eps=1e-38, type=Array{Float32}) where D
+ BatchNorm2d(channels::Int; inertia=0.9, eps=1e-38, type=Array{Float32}) where D
+ BatchNorm3d(channels::Int; inertia=0.9, eps=1e-38, type=Array{Float32}) where D
+ BatchNorm4d(channels::Int; inertia=0.9, eps=1e-38, type=Array{Float32}) where D
+ BatchNorm5d(channels::Int; inertia=0.9, eps=1e-38, type=Array{Float32}) where D
"""
mutable struct BatchNorm <: Normalizer
    Î³    :: VarOrNil                    # scaling params
    Î²    :: VarOrNil                    # shifting params
    Î¼    :: Union{AbstractArray,Nil}    # running average
    ÏƒÂ²   :: Union{AbstractArray,Nil}    # running variance
    Ïµ    :: AbstractFloat               # prevent zero-dividing
    Ï    :: AbstractFloat               # inertia coefficient
    dims :: NTuple                      # dims to collect elements for mean and variance
    function BatchNorm(;ndims    :: Int,                  # data dimentions
                        dim      :: Int,                  # channle dim
                        channels :: Int,                  # channle size
                        inertia  :: AbstractFloat=0.9,    # smoothing const or historical inertia
                        eps      :: AbstractFloat=1e-38,
                        type     :: Type=Array{Float32})

        shape, dims2reduce = bn_shape_and_rdims(ndims, dim, channels)
        Î³  = Variable{type}( Ones(type, shape), true, true, true)
        Î²  = Variable{type}(Zeros(type, shape), true, true, true)
        Î¼  = Zeros(type, shape)
        ÏƒÂ² =  Ones(type, shape)
        Ï  = eltype(type)(inertia)
        new(Î³, Î², Î¼, ÏƒÂ², eps, Ï, dims2reduce)
    end
    function BatchNorm(Ïµ::Real, Ï::Real, dims::Union{Tuple,Int})
        new(nothing, nothing, nothing, nothing, Ïµ, Ï, dims)
    end
end



function forward(b::BatchNorm, x::Variable)
    Î³ = b.Î³
    Î² = b.Î²

    xÌŒ, Î¼, ÏƒÂ² = znorm_mean_var(x, dims=b.dims, eps=b.Ïµ)
    y = xÌŒ .* Î³ .+ Î²

    T = eltype(x)
    l = T(1)
    Ï = T(b.Ï)

    ð  = b.Î¼
    ðˆÂ² = b.ÏƒÂ²
    @sync begin
        @async @. ð  = Ï * ð  + (l - Ï) * Î¼    # running mean
        @async @. ðˆÂ² = Ï * ðˆÂ² + (l - Ï) * ÏƒÂ²   # running var
    end
    return y
end


function predict(b::BatchNorm, x::AbstractArray)
    l  = eltype(x)(1)
    Î³  = áµ›(b.Î³)
    Î²  = áµ›(b.Î²)
    Î¼  = b.Î¼
    ÏƒÂ² = b.ÏƒÂ²

    xÌŒ = @. (x - Î¼) * (l / sqrt(ÏƒÂ²))
    y = @. xÌŒ * Î³ + Î²
    return y
end


function clone(this::BatchNorm; type::Type=Array{Float32})
    cloned    = BatchNorm(this.Ïµ, this.Ï, this.dims)
    cloned.Î³  = clone(this.Î³, type=type)
    cloned.Î²  = clone(this.Î², type=type)
    cloned.Î¼  = type(this.Î¼)
    cloned.ÏƒÂ² = type(this.ÏƒÂ²)
    return cloned
end

function Base.show(io::IO, bn::BatchNorm)
    S = length(bn.Î².value)
    T = typeof(bn.Î².value)
    D = length(bn.dims) - 1
    Ï = bn.Ï
    print(io, "BatchNorm$(D)d(channels=$S, inertia=$Ï; type=$T)")
end

function paramsof(bn::BatchNorm)
    params = Vector{Variable}(undef,2)
    params[1] = bn.Î³
    params[2] = bn.Î²
    return params
end

function xparamsof(bn::BatchNorm)
    xparams = Vector{XVariable}(undef,2)
    xparams[1] = ('w', bn.Î³)
    xparams[2] = ('b', bn.Î²)
    return xparams
end

function nparamsof(bn::BatchNorm)
    return 4*length(bn.Î²)
end

elsizeof(bn::BatchNorm) = elsizeof(bn.Î³)

function bytesof(bn::BatchNorm, unit::String="MB")
    n = nparamsof(bn) * elsizeof(bn)
    return blocksize(n, uppercase(unit))
end


for DIMS in [0,1,2,3,4,5]
    @eval begin
        export $(Symbol("BatchNorm$(DIMS)d"))
        function $(Symbol("BatchNorm$(DIMS)d"))(channels :: Int;
                                                eps      :: AbstractFloat=1e-38,
                                                inertia  :: AbstractFloat=0.9,
                                                type     :: Type=Array{Float32})
            return BatchNorm(;ndims=$(DIMS+2), dim=1, channels, eps, inertia, type)
        end
    end
end
